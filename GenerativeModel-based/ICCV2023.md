# Downstream-agnostic Adversarial Examples

## Abstract
文章针对传统任务中“先预训练再微调”的思路，提出：是否可以直接攻击预训练的Encoder，在下游任务和下游数据都未知的情况下得到一个通用对抗扰动（Universal Adversarial Perturbation, UAP）？文章甚至还假设可以在下游任务上微调以及可以采用防御性的对抗训练策略，进一步加大了任务难度。

## Method
训练一个生成器 $\mathcal{G}$ ，该生成器接受一个固定的噪声分布 $z$ 作为输入，并产生一个通用的攻击噪声，将它与一张干净图像结合则得到一个对抗样本。其本质是找了一个数据集，然后在该数据集上通过优化一个生成网络来得到一个UAP，并不是对每一张输入图片都产生一个与其对应的扰动。该训练过程使用3个loss来监督：

1）Quality loss：该扰动是否足够微小不可察觉？
2）HFC loss：该扰动是否破坏了原图像中的高频特征？（本文作者认为图像中的高频特征，例如纹理等，对分类器的正确识别至关重要）
3）Adv loss：预训练编码器提取到的特征是否有差别？
