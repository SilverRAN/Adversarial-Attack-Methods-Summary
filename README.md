# Adversarial-Attack-Methods-Summary

## News
ðŸ”¥[2024-07-04] Papers of CVPR 2024 have been updated!

## 2024
| **Title** | **Publish** | **Repo** | **Paper** | **Summary** |
|-----------|:-----------:|:--------:|:---------:|:-----------:|
| Towards Transferable Targeted 3D Adversarial Attack in the Physical World | *CVPR* | - | [![cvpr](https://img.shields.io/badge/pdf-thecvf-7395C5)](https://openaccess.thecvf.com/content/CVPR2024/html/Huang_Towards_Transferable_Targeted_3D_Adversarial_Attack_in_the_Physical_World_CVPR_2024_paper.html) | - |
| VA3: Virtually Assured Amplification Attack on Probabilistic Copyright Protection for Text-to-Image Generative Models | *CVPR* | - | [![cvpr](https://img.shields.io/badge/pdf-thecvf-7395C5)](https://openaccess.thecvf.com/content/CVPR2024/html/Li_VA3_Virtually_Assured_Amplification_Attack_on_Probabilistic_Copyright_Protection_for_CVPR_2024_paper.html) | - |
| Attack To Defend: Exploiting Adversarial Attacks for Detecting Poisoned Models | *CVPR* | - | [![cvpr](https://img.shields.io/badge/pdf-thecvf-7395C5)](https://openaccess.thecvf.com/content/CVPR2024/html/Fares_Attack_To_Defend_Exploiting_Adversarial_Attacks_for_Detecting_Poisoned_Models_CVPR_2024_paper.html) | - |
| On the Robustness of Large Multimodal Models Against Image Adversarial Attacks | *CVPR* | - | [![cvpr](https://img.shields.io/badge/pdf-thecvf-7395C5)](https://openaccess.thecvf.com/content/CVPR2024/html/Cui_On_the_Robustness_of_Large_Multimodal_Models_Against_Image_Adversarial_CVPR_2024_paper.html) | - |
| PAD: Patch-Agnostic Defense against Adversarial Patch Attacks | *CVPR* | [![Github](https://img.shields.io/github/stars/Lihua-Jing/PAD)](https://github.com/Lihua-Jing/PAD) | [![cvpr](https://img.shields.io/badge/pdf-thecvf-7395C5)](https://openaccess.thecvf.com/content/CVPR2024/html/Jing_PAD_Patch-Agnostic_Defense_against_Adversarial_Patch_Attacks_CVPR_2024_paper.html) | - |
| LOTUS: Evasive and Resilient Backdoor Attacks through Sub-Partitioning | *CVPR* | [![Github](https://img.shields.io/github/stars/Megum1/LOTUS)](https://github.com/Megum1/LOTUS) | [![cvpr](https://img.shields.io/badge/pdf-thecvf-7395C5)](https://openaccess.thecvf.com/content/CVPR2024/html/Cheng_LOTUS_Evasive_and_Resilient_Backdoor_Attacks_through_Sub-Partitioning_CVPR_2024_paper.html) | - |
| A Stealthy Wrongdoer: Feature-Oriented Reconstruction Attack against Split Learning | *CVPR* | - | [![cvpr](https://img.shields.io/badge/pdf-thecvf-7395C5)](https://openaccess.thecvf.com/content/CVPR2024/html/Xu_A_Stealthy_Wrongdoer_Feature-Oriented_Reconstruction_Attack_against_Split_Learning_CVPR_2024_paper.html) | - |
| BadCLIP: Trigger-Aware Prompt Learning for Backdoor Attacks on CLIP | *CVPR* | - | [![cvpr](https://img.shields.io/badge/pdf-thecvf-7395C5)](https://openaccess.thecvf.com/content/CVPR2024/html/Bai_BadCLIP_Trigger-Aware_Prompt_Learning_for_Backdoor_Attacks_on_CLIP_CVPR_2024_paper.html) | - |
| Deep-TROJ: An Inference Stage Trojan Insertion Algorithm through Efficient Weight Replacement Attack | *CVPR* | - | [![cvpr](https://img.shields.io/badge/pdf-thecvf-7395C5)](https://openaccess.thecvf.com/content/CVPR2024/html/Ahmed_Deep-TROJ_An_Inference_Stage_Trojan_Insertion_Algorithm_through_Efficient_Weight_CVPR_2024_paper.html) | - |
| MMCert: Provable Defense against Adversarial Attacks to Multi-modal Models | *CVPR* | - | [![cvpr](https://img.shields.io/badge/pdf-thecvf-7395C5)](https://openaccess.thecvf.com/content/CVPR2024/html/Wang_MMCert_Provable_Defense_against_Adversarial_Attacks_to_Multi-modal_Models_CVPR_2024_paper.html) | - |
| Physical Backdoor: Towards Temperature-based Backdoor Attacks in the Physical World | *CVPR* | - | [![cvpr](https://img.shields.io/badge/pdf-thecvf-7395C5)](https://openaccess.thecvf.com/content/CVPR2024/html/Yin_Physical_Backdoor_Towards_Temperature-based_Backdoor_Attacks_in_the_Physical_World_CVPR_2024_paper.html) | - |
| Physical 3D Adversarial Attacks against Monocular Depth Estimation in Autonomous Driving | *CVPR* | - | [![cvpr](https://img.shields.io/badge/pdf-thecvf-7395C5)](https://openaccess.thecvf.com/content/CVPR2024/html/Zheng_Physical_3D_Adversarial_Attacks_against_Monocular_Depth_Estimation_in_Autonomous_CVPR_2024_paper.html) | - |
| Re-thinking Data Availability Attacks Against Deep Neural Networks | *CVPR* | - | [![cvpr](https://img.shields.io/badge/pdf-thecvf-7395C5)](https://openaccess.thecvf.com/content/CVPR2024/html/Fang_Re-thinking_Data_Availability_Attacks_Against_Deep_Neural_Networks_CVPR_2024_paper.html) | - |
| Leak and Learn: An Attacker's Cookbook to Train Using Leaked Data from Federated Learning | *CVPR* | - | [![cvpr](https://img.shields.io/badge/pdf-thecvf-7395C5)](https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_Leak_and_Learn_An_Attackers_Cookbook_to_Train_Using_Leaked_CVPR_2024_paper.html) | - |
| Defense Against Adversarial Attacks on No-Reference Image Quality Models with Gradient Norm Regularization | *CVPR* | - | [![cvpr](https://img.shields.io/badge/pdf-thecvf-7395C5)](https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Defense_Against_Adversarial_Attacks_on_No-Reference_Image_Quality_Models_with_CVPR_2024_paper.html) | - |
| Semantic-Aware Multi-Label Adversarial Attacks | *CVPR* | - | [![cvpr](https://img.shields.io/badge/pdf-thecvf-7395C5)](https://openaccess.thecvf.com/content/CVPR2024/html/Mahmood_Semantic-Aware_Multi-Label_Adversarial_Attacks_CVPR_2024_paper.html) | - |
| Nearest is Not Dearest: Towards Practical Defense against Quantization-conditioned Backdoor Attacks | *CVPR* | - | [![cvpr](https://img.shields.io/badge/pdf-thecvf-7395C5)](https://openaccess.thecvf.com/content/CVPR2024/html/Li_Nearest_is_Not_Dearest_Towards_Practical_Defense_against_Quantization-conditioned_Backdoor_CVPR_2024_paper.html) | - |
| Overload: Latency Attacks on Object Detection for Edge Devices | *CVPR* | - | [![cvpr](https://img.shields.io/badge/pdf-thecvf-7395C5)](https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Overload_Latency_Attacks_on_Object_Detection_for_Edge_Devices_CVPR_2024_paper.html) | - |
| Data Poisoning based Backdoor Attacks to Contrastive Learning | *CVPR* | - | [![cvpr](https://img.shields.io/badge/pdf-thecvf-7395C5)](https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Data_Poisoning_based_Backdoor_Attacks_to_Contrastive_Learning_CVPR_2024_paper.html) | - |
| Intriguing Properties of Diffusion Models: An Empirical Study of the Natural Attack Capability in Text-to-Image Generative Models | *CVPR* | - | [![cvpr](https://img.shields.io/badge/pdf-thecvf-7395C5)](https://openaccess.thecvf.com/content/CVPR2024/html/Sato_Intriguing_Properties_of_Diffusion_Models_An_Empirical_Study_of_the_CVPR_2024_paper.html) | - |
| MMA-Diffusion: MultiModal Attack on Diffusion Models | *CVPR* | [![Github](https://img.shields.io/github/stars/cure-lab/MMA-Diffusion)](https://github.com/cure-lab/MMA-Diffusion) | [![cvpr](https://img.shields.io/badge/pdf-thecvf-7395C5)](https://openaccess.thecvf.com/content/CVPR2024/html/Yang_MMA-Diffusion_MultiModal_Attack_on_Diffusion_Models_CVPR_2024_paper.html) | - |
| Strong Transferable Adversarial Attacks via Ensembled Asymptotically Normal Distribution Learning | *CVPR* | - | [![cvpr](https://img.shields.io/badge/pdf-thecvf-7395C5)](https://openaccess.thecvf.com/content/CVPR2024/html/Fang_Strong_Transferable_Adversarial_Attacks_via_Ensembled_Asymptotically_Normal_Distribution_Learning_CVPR_2024_paper.html) | - |
| Transferable Structural Sparse Adversarial Attack Via Exact Group Sparsity Training | *CVPR* | [![Github](https://img.shields.io/github/stars/MisterRpeng/EGS-TSSA)](https://github.com/MisterRpeng/EGS-TSSA) | [![cvpr](https://img.shields.io/badge/pdf-thecvf-7395C5)](https://openaccess.thecvf.com/content/CVPR2024/html/Ming_Transferable_Structural_Sparse_Adversarial_Attack_Via_Exact_Group_Sparsity_Training_CVPR_2024_paper.html) | - |
| Adversarial Backdoor Attack by Naturalistic Data Poisoning on Trajectory Prediction in Autonomous Driving | *CVPR* | - | [![cvpr](https://img.shields.io/badge/pdf-thecvf-7395C5)](https://openaccess.thecvf.com/content/CVPR2024/html/Pourkeshavarz_Adversarial_Backdoor_Attack_by_Naturalistic_Data_Poisoning_on_Trajectory_Prediction_CVPR_2024_paper.html) | - |
| SlowFormer: Adversarial Attack on Compute and Energy Consumption of Efficient Vision Transformers | *CVPR* | - | [![cvpr](https://img.shields.io/badge/pdf-thecvf-7395C5)](https://openaccess.thecvf.com/content/CVPR2024/html/Navaneet_SlowFormer_Adversarial_Attack_on_Compute_and_Energy_Consumption_of_Efficient_CVPR_2024_paper.html) | - |
| Not All Prompts Are Secure: A Switchable Backdoor Attack Against Pre-trained Vision Transfomers | *CVPR* | [![Github](https://img.shields.io/github/stars/UCDvision/SlowFormer)](https://github.com/UCDvision/SlowFormer) | [![cvpr](https://img.shields.io/badge/pdf-thecvf-7395C5)](https://openaccess.thecvf.com/content/CVPR2024/html/Navaneet_SlowFormer_Adversarial_Attack_on_Compute_and_Energy_Consumption_of_Efficient_CVPR_2024_paper.html) | - |
| GLOW: Global Layout Aware Attacks on Object Detection | *CVPR* | - | [![cvpr](https://img.shields.io/badge/pdf-thecvf-7395C5)](https://openaccess.thecvf.com/content/CVPR2024/html/Bao_GLOW_Global_Layout_Aware_Attacks_on_Object_Detection_CVPR_2024_paper.html) | - |
| Improving Transferable Targeted Adversarial Attacks with Model Self-Enhancement | *CVPR* | [![Github](https://img.shields.io/github/stars/g4alllf/SASD)](https://github.com/g4alllf/SASD) | [![cvpr](https://img.shields.io/badge/pdf-thecvf-7395C5)](https://openaccess.thecvf.com/content/CVPR2024/html/Wu_Improving_Transferable_Targeted_Adversarial_Attacks_with_Model_Self-Enhancement_CVPR_2024_paper.html) | - |
| BrainWash: A Poisoning Attack to Forget in Continual Learning | *CVPR* | [![Github](https://img.shields.io/github/stars/mint-vu/Brainwash)](https://github.com/mint-vu/Brainwash) | [![cvpr](https://img.shields.io/badge/pdf-thecvf-7395C5)](https://openaccess.thecvf.com/content/CVPR2024/html/Abbasi_BrainWash_A_Poisoning_Attack_to_Forget_in_Continual_Learning_CVPR_2024_paper.html) | - |
| BadCLIP: Dual-Embedding Guided Backdoor Attack on Multimodal Contrastive Learning | *CVPR* | [![Github](https://img.shields.io/github/stars/LiangSiyuan21/BadCLIP)](https://github.com/LiangSiyuan21/BadCLIP) | [![cvpr](https://img.shields.io/badge/pdf-thecvf-7395C5)](https://openaccess.thecvf.com/content/CVPR2024/html/Liang_BadCLIP_Dual-Embedding_Guided_Backdoor_Attack_on_Multimodal_Contrastive_Learning_CVPR_2024_paper.html) | - |

## 2023
| **Title** | **Publish** | **Repo** | **Paper** | **Summary** |
|-----------|:-----------:|:--------:|:---------:|:-----------:|
| Content-based Unrestricted Adversarial Attack | *NeurIPS* | - | [![arxiv](https://img.shields.io/badge/arXiv-2305.10665-b13b1b)](https://arxiv.org/abs/2305.10665) | [summary](Semantic-Methods/Cont_UAA.md) |
| Diff-PGD: Diffusion-Based Adversarial Sample Generation for Improved Stealthiness and Controllability | *NeurIPS* | [![Github](https://img.shields.io/github/stars/xavihart/Diff-PGD)](https://github.com/xavihart/Diff-PGD) | [![arxiv](https://img.shields.io/badge/arXiv-2305.16494-b13b1b)](https://arxiv.org/abs/2305.16494) | [summary](GenerativeModel-based/Diff-PGD.md) |
| Downstream-agnostic Adversarial Examples | *ICCV* | [![Github](https://img.shields.io/github/stars/CGCL-codes/AdvEncoder)](https://github.com/CGCL-codes/AdvEncoder) | [![arxiv](https://img.shields.io/badge/arXiv-2307.12280-b13b1b)](https://arxiv.org/abs/2307.12280) <br /> [![iccv](https://img.shields.io/badge/pdf-thecvf-7395C5)](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Downstream-agnostic_Adversarial_Examples_ICCV_2023_paper.html) |  |
| AdvDiffuser: Natural Adversarial Example Synthesis with Diffusion Models | *ICCV* | [![Github](https://img.shields.io/github/stars/lafeat/advdiffuser)](https://github.com/lafeat/advdiffuser) |  [![arxiv](https://img.shields.io/badge/arXiv-2307.12499-b13b1b)](https://arxiv.org/abs/2307.12499) <br /> [![iccv](https://img.shields.io/badge/pdf-thecvf-7395C5)](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_AdvDiffuser_Natural_Adversarial_Example_Synthesis_with_Diffusion_Models_ICCV_2023_paper.html) | [summary](GenerativeModel-based/AdvDiffuser.md) |
| Frequency-aware GAN for Adversarial Manipulation Generation | *ICCV* | - | [![iccv](https://img.shields.io/badge/pdf-thecvf-7395C5)](https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Frequency-aware_GAN_for_Adversarial_Manipulation_Generation_ICCV_2023_paper.html) |  |
| AdvDiff: Generating Unrestricted Adversarial Examples using Diffusion Models | - | [![Github](https://img.shields.io/github/stars/EricDai0/advdiff)](https://github.com/EricDai0/advdiff) | [![arxiv](https://img.shields.io/badge/arXiv-2307.12499-b13b1b)](https://arxiv.org/abs/2307.12499) | [summary](GenerativeModel-based/AdvDiff.md) |
| Diffusion Models for Imperceptible and Transferable Adversarial Attack | - | [![Github](https://img.shields.io/github/stars/WindVChen/DiffAttack)](https://github.com/WindVChen/DiffAttack) | [![arxiv](https://img.shields.io/badge/arXiv-2305.08192-b13b1b)](https://arxiv.org/abs/2305.08192) |  |
| Semantic Adversarial Attacks via Diffusion Models | *BMVC* | [![Github](https://img.shields.io/github/stars/steven202/semantic_adv_via_dm)](https://github.com/steven202/semantic_adv_via_dm) | [![arixv](https://img.shields.io/badge/arXiv-2309.07398-b13b1b)](https://arxiv.org/abs/2309.07398) | [summary](Semantic-Methods/semantic_adv_via_dm.md) |

## 2022
| **Title** | **Publish** | **Repo** | **Paper** | **Summary** |
|-----------|:-----------:|:--------:|:---------:|:-----------:|
| SegPGD: An Effective and Efficient Adversarial Attack for Evaluating and Boosting Segmentation Robustness | *ECCV* |  | [![arXiv](https://img.shields.io/badge/arXiv-2207.12391-b13b1b)](https://arxiv.org/abs/2207.12391) | - |
| Natural color fool: Towards boosting black-box unrestricted attacks | *NeurIPS* | - | - | - |
| Sparse Black-Box Video Attack with Reinforcement Learning | *IJCV* |  | [![Springer](https://img.shields.io/badge/pdf-Spinger-orange)](https://link.springer.com/article/10.1007/s11263-022-01604-w) |  |
| Attacking Video Recognition Models with Bullet-Screen Comments | *AAAI* |  | [![arXiv](https://img.shields.io/badge/arXiv-2110.15629-b13b1b)](https://arxiv.org/abs/2110.15629) <br /> [![aaai](https://img.shields.io/badge/aaai-org-blue)](https://ojs.aaai.org/index.php/AAAI/article/view/19907) |  |

## 2021
| **Title** | **Publish** | **Repo** | **Paper** | **Summary** |
|-----------|:-----------:|:--------:|:---------:|:-----------:|
| Towards Feature Space Adversarial Attack | ** |  |  | [summary]((GenerativeModel-based/Towards-Feature-Space-Adversarial-Attack.md)) |

## 2020
| **Title** | **Publish** | **Repo** | **Paper** | **Summary** |
|-----------|:-----------:|:--------:|:---------:|:-----------:|
| Unrestricted Adversarial Examples via Semantic Manipulation | *ICLR* |  |  | [summary](Semantic-Methods/Color_Texture_Attack.md) |
| SemanticAdv: Generating Adversarial Examples via Attribute-conditioned Image Editing | *ECCV* |  |  | [summary](Semantic-Methods/SemanticAdv.md) |
| Colorfool: Semantic adversarial colorization | *CVPR* | - | - | - |

## 2019
| **Title** | **Publish** | **Repo** | **Paper** | **Summary** |
|-----------|:-----------:|:--------:|:---------:|:-----------:|
| Semantic Adversarial Attacks: Parametric Transformations That Fool Deep Classifiers | *ICCV* |  |  | [summary](Semantic-Methods/SAA.md) |
| Rob-GAN: Generator, Discriminator, and Adversarial Attacker | *CVPR* |  |  | [summary](GenerativeModel-based/Rob-GAN.md) |
| ADef: an Iterative Algorithm to Construct Adversarial Deformations | *ICLR* | - | - | - |
| AdvGAN++: Harnessing Latent Layers for Adversary Generation | *CVPRW* |  |  | [summary](GenerativeModel-based/AdvGAN++.md) |
| One pixel attack for fooling deep neural networks | *IEEE TEVC* | - | - | - |

## ~2018

| **Title** | **Publish** | **Repo** | **Paper** | **Summary** |
|-----------|:-----------:|:--------:|:---------:|:-----------:|
| Intriguing Properties of Neural Networks. | *ICLR 2014* | - | [![arXiv](https://img.shields.io/badge/arXiv-1312.6199-b13b1b)](https://arxiv.org/abs/1312.6199) <br /> [![ICLR](https://img.shields.io/badge/pdf-OpenReview-green)](https://openreview.net/forum?id=kklr_MTHMRQjG) | [summary](Gradient-based/Intriguing-properties-of-neural-networks.md) |
| FGSM: Explaining and Harnessing Adversarial Examples | *ICLR 2015* | - |  | [summary](Gradient-based/FGSM.md) |
| Deepfool: a simple and accurate method to fool deep neural networks | *CVPR 2016* |  | [![cvpr](https://img.shields.io/badge/pdf-thecvf-7395C5)](https://openaccess.thecvf.com/content_cvpr_2016/html/Moosavi-Dezfooli_DeepFool_A_Simple_CVPR_2016_paper.html) | - |
| Universal adversarial perturbations | *CVPR 2017* | - | [![cvpr](https://img.shields.io/badge/pdf-thecvf-7395C5)](https://openaccess.thecvf.com/content_cvpr_2017/html/Moosavi-Dezfooli_Universal_Adversarial_Perturbations_CVPR_2017_paper.html) |  |
| Towards evaluating the robustness of neural networks | *2017 IEEE Symposium on Security and Privacy (SP)* | - | - | - |
| Ensemble Adversarial Training: Attacks and Defenses | *ICLR 2018* | - | [![arXiv](https://img.shields.io/badge/arXiv-1706.06083-b13b1b)]([https://arxiv.org/abs/1706.06083](https://arxiv.org/abs/1705.07204)) | - |
| PGD: Towards Deep Learning Models Resistant to Adversarial Attacks | *ICLR 2018* |  | [![arXiv](https://img.shields.io/badge/arXiv-1706.06083-b13b1b)](https://arxiv.org/abs/1706.06083) | - |
| Generating Natural Adversarial Examples | *ICLR 2018* |  |  | [summary](GenerativeModel-based/Generating-Natural-Adversarial-Examples.md) |
| Constructing Unrestricted Adversarial Examples with Generative Models | *NeurIPS 2018* |  |  | [summary](GenerativeModel-based/Constructing-Unrestricted-Adversarial-Examples-with-Generative-Models.md) |
| NAG: Network for Adversary Generation | *CVPR 2018* | [![Github](https://img.shields.io/github/stars/val-iisc/nag)](https://github.com/val-iisc/nag) | [![cvpr](https://img.shields.io/badge/pdf-thecvf-7395C5)](https://openaccess.thecvf.com/content_cvpr_2018/html/Mopuri_NAG_Network_for_CVPR_2018_paper.html) | [summary](GenerativeModel-based/CVPR2018.md) |
| Semantic Adversarial Examples | *CVPRW 2018* |  |  | [summary](Semantic-Methods/SAE.md) |
| AdvGAN: Generating adversarial examples with adversarial networks | *IJCAI 2018* | [![Github](https://img.shields.io/github/stars/mathcbc/advGAN_pytorch)](https://github.com/mathcbc/advGAN_pytorch) | [![arxiv](https://img.shields.io/badge/arXiv-1801.02610-b13b1b)](https://arxiv.org/abs/1801.02610) <br /> [![ijcai](https://img.shields.io/badge/pdf-ijcai-navy)](https://www.ijcai.org/proceedings/2018/0543) | [summary](GenerativeModel-based/AdvGAN.md) |
| ATN: Learning to Attack: Adversarial Transformation Networks | *AAAI 2018* | [![Github](https://img.shields.io/github/stars/RanTaimu/Adversarial-Transformation-Network)](https://github.com/RanTaimu/Adversarial-Transformation-Network) | [![arixv](https://img.shields.io/badge/arXiv-1703.09387-b13b1b)](https://arxiv.org/abs/1703.09387) <br /> [![aaai](https://img.shields.io/badge/aaai-org-blue)](https://ojs.aaai.org/index.php/AAAI/article/view/11672) | [summary](GenerativeModel-based/AAAI2018.md) |
